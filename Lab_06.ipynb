{
 "cells": [
  {
   "cell_type": "code",
   "source": "pip install ",
   "metadata": {
    "cell_id": "c345ba0bfb064d50ab36c37b9c6bce39",
    "tags": [],
    "deepnote_cell_type": "code",
    "deepnote_cell_height": 66
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "# Lab 06 - Nighttime Lights Appendix\n\n## Overview\n\nCapturing and visualizing low-light emittance from around the earth has been utilized in various applications since the mid-1960's. By consistently quantifying light emittance over long time periods, it is possible to use this as a proxy for economic development, especially in areas where there is not high-quality data and metrics to work with. Google Earth Engine has consolidated this data into an operational archive dating back to 1992, which provides unparallelled support for finding meaningful insights using this data set.\n\nThis tutorial is a supplement to the *Open Nighttime Lights* [tutorial](https://worldbank.github.io/OpenNightLights/welcome.html) that the World Bank developed. The World Bank tutorial consists of six modules, including a background on the history of the data, working with the tools, extracting imagery, data analysis and image classification. It also contains an archive in which you can archive the raw data directly from Amazon Web Services and an applications section that attempts to estimate electricity usage using the nighttime data set. Each segment is well-written, and there is extensive documentation throughout. \n\nThe caveat here is that up until this point in the course, we have worked with the Google Earth Engine JavaScript code editor - Because the World Bank tutorial covers topics such as working with data frames, statistics and classification, it utilizes the Google Earth Engine Python API in a Jupyter Notebook. Python is a more natural fit and contains more capabilities for data analysis and Machine Learning than JavaScript, and while the GEE code editor is excellent for working with objects and methods, many of you might prefer working with Python. Based on your background and what you want to get out of this course, here is our general suggestion on how to proceed. \n\n1. If you are comfortable working with Python, Jupyter Notebooks and setting up your own environment (pip, Conda, Brew), then follow along with the tutorial as it is. Module 2-2 in the World Bank tutorial explains how to get an environment up and running.\n   1. If this is the case, spend some time reading about the functionality in the [geemap](https://geemap.org) package - it consolidates much of the mapping features in Earth Engine in an intuitive way, as well as functionality to integrate your results with Folium and custom basemaps.\n\n2. If you want to learn to use Python but have never worked with virtual environments, then consider going through the tutorial in a Google Colab - it requires no setup of infrastructure, and you can get running immediately while learning Python. Once you are comfortable with this, you can always learn how to set up your own environment. Explanations on getting started can be located [here](https://worldbank.github.io/OpenNightLights/tutorials/mod2_3_introduction_to_Jupyter_notebooks.html). Note that there are several components of the tutorial, primarily in visualization using leaflet, that will not work. \n3. If you want to stick with working with JavaScript, then the section below will provide you with some capabilities of doing the core functions in the code editor, mainly the segment in Module 3. After that, we suggest exporting the data for further analysis. \n\nAgain, this lab is more of a supplement for students that wish to keep using JavaScript and the GEE code editor. It is not designed to fully replace the World Bank tutorial, and while will get you started, there will be things that you will have to figure out on your own. \n\n## Basic Operations \n\nModule 1 is an essential introduction to the NightTime Lights dataset, while Module 2 introduces you to the data and the setting up your environment. In this section, we will covering the essential components of obtaining the data that you need in the correct context, some basic processing, building a composite and exporting the data  in JavaScript, with enough code to show you how to get started and how to follow along with the tutorial. \n\nWe will follow along with module exactly as it is set up,  so that you can refer to the Module and section numbers. \n\n1. **Obtaining the Data**\n\n   The code chunk below should be a good starting point on ingesting the data, looking at the range of data, and visualizing the average value across the image collection. Follow along with the same concepts in the tutorial, test using a specific image (instead of an image collection) and visualize your results. You can modify the opacity manually using the slider on the `layers` tab, and then build it into your [visualization](https://developers.google.com/earth-engine/guides/image_visualization?hl=en#code-editor-javascript).\n\n   Note: JavaScript uses Lon / Lat, while Python uses lat / long while building points or setting map areas. \n\n```javascript\n// Read in Nighttime Lights\nvar dmsp = ee.ImageCollection(\"NOAA/DMSP-OLS/NIGHTTIME_LIGHTS\");\n// Print size of the image collection\nprint(dmsp.size());\n// Print out the dates of image collection\nvar imgrange = dmsp.reduceColumns(ee.Reducer.minMax(), [\"system:time_start\"]);\nvar start = ee.Date(imgrange.get('min'));\nvar end = ee.Date(imgrange.get('max'));\nprint('Date range: ', start, end);\n// Take average visibility \nvar nighttimeLights = dmsp.select('avg_vis');\nvar nighttimeLightsVis = {\n  min: 3.0,\n  max: 60.0,\n};\nvar center_lat = 38.9072;\nvar center_lon = -77.0369;\nvar zoomlevel=7;\n// \nMap.setCenter(center_lon, center_lat, zoomlevel);\nMap.addLayer(nighttimeLights, nighttimeLightsVis, 'Nighttime Lights');\n```\n\n2. **Image Clipping**\n\n   This section follows along with some of our earlier work in clipping our image to a certain area. Whether you need to bring in your own shapefiles. The code below [clips](https://developers.google.com/earth-engine/apidocs/ee-image-clip) the imagery within a 200km buffer on the center of Los Angeles. \n\n```javascript\n// Get December image - \"avg_rad\" band\nvar viirs2019_12 = ee.ImageCollection(\"NOAA/VIIRS/DNB/MONTHLY_V1/VCMSLCFG\").filterDate(\n  \"2019-12-01\",\"2019-12-31\").select('avg_rad').median()\n// Set visibility parameters\nvar nighttimeLightsVis = {\n  min: 3.0,\n  max: 60.0,\n};\nvar center_lat = 34.05;\nvar center_lon = -118.25;\n// Build a 200km buffer around a point\n// Clip image to boundary of buffer\nvar aoi = ee.Geometry.Point([center_lon, center_lat]).buffer(200000);\nvar viirs2019_12_clipped = viirs2019_12.clip(aoi)\nvar zoomlevel=7;\n// map set center \nMap.setCenter(center_lon, center_lat, zoomlevel);\nMap.addLayer(viirs2019_12_clipped, nighttimeLightsVis, 'Clipped to Buffer');\n```\n\n![Clip to Point Buffer](./im/im_06_01.png)\n\nYou can do the same thing with either your own polygon vector files (import shapefile, kml), or use one of the vector files that GEE maintains - we can test use the TIGER state boundary file and clip the image to California. \n\n```javascript\n// Get December image - \"avg_rad\" band\nvar viirs2019_12 = ee.ImageCollection(\"NOAA/VIIRS/DNB/MONTHLY_V1/VCMSLCFG\").filterDate(\n  \"2019-12-01\",\"2019-12-31\").select('avg_rad').median()\n// Set visibility parameters\nvar nighttimeLightsVis = {\n  min: 3.0,\n  max: 60.0,\n};\nvar center_lat = 37;\nvar center_lon = -120;\n// Boundary of states\n// Filter to California \nvar aoi_CA = ee.FeatureCollection('TIGER/2016/States').filter(\n  ee.Filter.eq('NAME', 'California'))\nvar viirs2019_12_clipped = viirs2019_12.clip(aoi_CA)\nvar zoomlevel=6;\n// map set center \nMap.setCenter(center_lon, center_lat, zoomlevel);\nMap.addLayer(viirs2019_12_clipped, nighttimeLightsVis, 'California NightTime Lights'); \n```\n\n![Clip to Feature](./im/im_06_02.png)\n\nThe previous two examples showed the process of clipping individual images - to clip an entire image \t\tcollection and extract a composite image, we can follow the same general approach, but use the `map` function to clip each image of the collection to our boundary. However, note that depending on the use case and the size of the image collection, this might take time to run and still leave you with a large amount of data. Before exporting all the data, perhaps reduce the image collection by extracting mean / median values, or use the reduce function. \n\n```javascript\nvar viirsDNB = ee.ImageCollection(\"NOAA/VIIRS/DNB/MONTHLY_V1/VCMSLCFG\").select('avg_rad')\n// Define our clipping function\n// Built specifically for the purposes of clipping to California\nfunction clip_func(im_col) {\n    return im_col.clip(aoi_CA);\n}\n// Set visibility parameters\nvar nighttimeLightsVis = {\n  min: 3.0,\n  max: 60.0,\n};\nvar center_lat = 37;\nvar center_lon = -120;\nvar zoomlevel=6;\n// Boundary of States\n// Filter to California \nvar aoi_CA = ee.FeatureCollection('TIGER/2016/States').filter(\n  ee.Filter.eq('NAME', 'California'))\n// use `map` - which applied our function to each image in the image collection\nvar viirs_dmb_clipped = viirsDNB.map(clip_func)\n// map set center \nMap.setCenter(center_lon, center_lat, zoomlevel);\nMap.addLayer(viirs_dmb_clipped, nighttimeLightsVis, 'California NightTime Lights');\n```\n\n3. **Conditional Operations**\n\nIn this section, we will go over how to mask individual pixels based on conditional statements. This is one section that we will cover in JavaScript, but is probably easier to conduct in Python using 'Pythonic' methods and libraries such as NumPy. The charting is easer to work with in Python, but in the code chunk below, you can go through how to build a histogram smoothed with a Gaussian filter to identify where a value to might be appropriate. Then, build a binary mask using GEE's built in conditionals:  \n\n```javascript\n// get December image, we're using the \"avg_rad\" band\nvar viirs2019_12 = ee.ImageCollection(\"NOAA/VIIRS/DNB/MONTHLY_V1/VCMSLCFG\").filterDate(\n  \"2019-12-01\",\"2019-12-31\").select('avg_rad').median()\n// center on Catalonia\nvar lat = 41.83\nvar lon = 1.67\n// create a 200 km buffer around the center of Catalonia\nvar aoi = ee.Geometry.Point(lon, lat).buffer(200000);\n```\n\n**Build the Histogram**\n\nThis histogram is quite tough to read, but there are values that range from 0 to over 1000 - note that the vast majority fall within the range of 0 and 4. This is used to get a basic understanding of our data. \n\n--------> Need to improve\n\n```javascript\n// \nvar hist = viirs2019_12.reduceRegion({\n  reducer: ee.Reducer.autoHistogram(),\n  geometry: aoi,\n  scale: 100,\n  bestEffort: true\n});\n// The result of the region reduction by `autoHistogram` is an array. Get the\n// array and cast it as such for good measure.\nvar histArray = ee.Array(hist.get('avg_rad')) ;\nprint(histArray)\n// Subset the values that represent the bottom of the bins and project to\n// a single dimension. Result is a 1-D array.\nvar binBottom = histArray.slice(1, 0, 1).project([0]);\n// Subset the values that represent the number of pixels per bin and project to\n// a single dimension. Result is a 1-D array.\nvar nPixels = histArray.slice(1, 1, null).project([0]);\n// Chart the two arrays using the `ui.Chart.array.values` function.\nvar histColumnFromArray = ui.Chart.array.values({\n  array:nPixels,\n  axis: 0,\n  xLabels: binBottom})\n  .setChartType('ColumnChart');\nprint(histColumnFromArray);\n```\n\n**Mask values**\n\nThe histogram shows us that a a large majority of the values fall near zero - if we build a mask using GEE's built in conditionals to keep only pixels that have a value above 4, the output allows us to focus in on areas that have meaningful values. Additionally, this will improve compute time and analysis. \n\n```javascript\n// Output is a binary mask (0-1)\nvar mask_value = 4\nvar viirs2019_12_mask = viirs2019_12.gte(mask_value)\n// Initialize our map\nvar nighttimeVis = {min: 0.0, max: 120.0};\nMap.setCenter(lon, lat, 8);\nMap.addLayer(viirs2019_12.mask(viirs2019_12_mask), nighttimeVis,  'Nighttime');\n```\n\n![Mask Values](./im/im_06_03.png)\n\nNote that just like in the lab, you can chain together conditionals to make a layered mask, and build a customized pallette. \n\n```javascript\nvar zones = viirs2019_12.gt(1.5).add(viirs2019_12.gt(2)).add(viirs2019_12.gt(5))\n// Initialize our map\nvar nighttimeVis = {min: 0.0, max: 120.0};\nMap.setCenter(lon, lat, 8);\nMap.addLayer(zones.mask(zones), {'palette':['#cc0909','#e67525','#fff825']}, 'zones');\n```\n\n![Layered Mask](./im/im_06_04.png)\n\n4. **Cell Statistics and Band Math**\n\nIt is worthwhile to read through this section thoroughly on the World Bank tutorial, as the techniques you learn here will be very useful in later sections. We will go over scaling an image to center each pixel at zero. We are working in the region of East Timor - the general process is to read in the December 2017 Nighttime Lights average, clip it to the East Timor Feature Collection, and then calculate the mean and standard deviation using the `reduceRegion` function. Now that we have those values, we can standardize the scaling. Compare the before and after images - in the first, it is very difficult to get any meaningful values, because the range of values is so narrow. Once scaled, we can more easily differentiate between urban areas and rural areas. You will also note that by doing this, the noise increases as well, as you can tell from the reduced 'sharpness' of the image. This can be an issue in many cases, and will be addressed in other components of the module. \n\n```javascript\n// get December image, we're using the \"avg_rad\" band\nvar viirs2017_12 = ee.ImageCollection(\n  \"NOAA/VIIRS/DNB/MONTHLY_V1/VCMSLCFG\").filterDate(\n  \"2017-12-01\",\"2017-12-31\").select('avg_rad').first()\n// get the geometry for Timor-Leste from GEE's tagged datasets\nvar tls = ee.Feature(ee.FeatureCollection(\n  \"FAO/GAUL/2015/level0\").filter(ee.Filter.eq(\n  'ADM0_NAME', 'Timor-Leste')).first()).geometry()\n// clip our VIIRS image to Timor-Leste\nvar ntl_tls = viirs2017_12.clip(tls)\n// Set visibility parameters\nvar nighttimeLightsVis = {\n  min: 3.0,\n  max: 60.0,\n};\nMap.setCenter(126.25, -8.5, 9);\nMap.addLayer(ntl_tls, nighttimeLightsVis, '\"VIIRS-DNB Dec 2017\"');\n```\n\n![Scaling Image](./im/im_06_05.png)\n\n```javascript\n// Reduce image to find the mean and standard deviation\nvar mu = ntl_tls.reduceRegion(ee.Reducer.mean())\nvar std = ntl_tls.reduceRegion(ee.Reducer.stdDev())\n// Convert these to Numbers using the ee.Number constructor\nvar mu = ee.Number(mu.get('avg_rad'))\nvar std = ee.Number(std.get('avg_rad'))\n// Print Output to ensure values look correct\nprint('Mean Avg Radiance', mu.getInfo())\nprint('StdDev', std.getInfo())\n// Subtract mean and divide by standard deviation\nvar ntl_tls_std = ntl_tls.subtract(mu).divide(std)\n// Set visibility parameters\nvar nighttimeLightsVis = {\n  min: -4,\n  max: 4,\n};\nMap.setCenter(126.25, -8.5, 9);\nMap.addLayer(ntl_tls_std, nighttimeLightsVis, 'Scaled Image');\n```\n\n![Rescaled Image](./im/im_06_06.png)\n\n5. **Expressions**\n\nIn this module, we will work with the `.expression()` methods built-into images. This allows us to work with customized functions and complete more advanced band math than pre-built functionality. This is a very short module, but the key point here is that being able to manipulate and find unique relationships in imagery. Once you understand how to build an expression, opportunities are limitless. In the images below, we invert the pixel values by multiplying each pixel by -1 and adding 63 (max value). \n\n```javascript\n// get 1996 composite, apply mask, and add as layer\nvar dmsp1996 = ee.Image(\"NOAA/DMSP-OLS/NIGHTTIME_LIGHTS/F121996\").select('stable_lights')\nvar lat = 19.43\nvar lon = -99.13\nvar nighttimeLightsVis = {\n  min: 0.0,\n  max: 63.0,\n};\nMap.setCenter(lon, lat, 7);\nMap.addLayer(dmsp1996, nighttimeLightsVis, '1996 Composite')\n```\n\n![Before Inversion](./im/im_06_07.png)\n\n```javascript\n// Use Expression to invert the pixels\nvar dmsp1996_inv = dmsp1996.multiply(-1).add(63)\nMap.addLayer(dmsp1996_inv, nighttimeLightsVis, '1996 Composite Inverse')\n```\n\n ![Inverted Image](./im/im_06_08.png)\n\n6. **Expression (Continued)**\n\nIn the previous example we built an expression using some of the GEE built-in operations, such as `.multiplication()` and `.add()`. This works well for that specific use case, but is limiting when you need to use operations that are not specifically provided within GEE. Another methodology is to build our expression with a string and then provide the input as a key-value pair. See the code chunk below for the methodology. Additionally, for calculations that involve massive amounts of data, there are some speed advantages in doing it this way. Follow along with the World Bank tutorial using this methodology, and try to build some of your own functions to see the result. Using 'Inspector' would be helpful to test whether your function acted as expected. \n\n```javascript\nvar inv_formula = \"(X*-1) + 63\"\n// We plug this formula in, identify our variable \"X\" and set it to our 1996 DMSP-OLS \"stable_lights\" band\nvar dmsp1996_inv2 = dmsp1996.expression(inv_formula, {'X':dmsp1996})\nMap.addLayer(dmsp1996_inv2, nighttimeLightsVis, '1996 Composite Inverse')\n```\n\n7. **Make a Composite**\n\nBuilding a temporal composite is an important part of analysis and modeling. We went through these concepts in earlier labs, although this tutorial extends some of the functionality. \n\n```javascript\n// 2015 image collection - \"avg_rad\" band\nvar viirs2015 = ee.ImageCollection(\"NOAA/VIIRS/DNB/MONTHLY_V1/VCMSLCFG\").filterDate(\n  \"2015-01-01\",\"2015-12-31\").select('avg_rad')\n// Confirm that there are 12 images in this collection \nprint('Images:', viirs2015.size().getInfo())\nvar viirs2015med = viirs2015.median()\n// iniatialize map on Sao Paulo\nvar lat = -23.54\nvar lon = -46.63\nvar nighttimeLightsVis = {\n  min: 0.0,\n  max: 63.0,\n};\n// Initialize the map\nMap.setCenter(lon, lat, 7);\nMap.addLayer(viirs2015med.mask(viirs2015med), nighttimeLightsVis, '2015 Monthly Median')\n```\n\n![Composite Image](./im/im_06_09.png)\n\n------> Research alternative to loop - convert function in 7.4.3 to `.map`\n\n```javascript\n// Define start and end years\nvar start = 2015\nvar end = 2019\nvar years = ee.List.sequence(start, end)\nprint('Number of years: ', years.size().getInfo())\nvar colID = \"NOAA/VIIRS/DNB/MONTHLY_V1/VCMSLCFG\"\nfunction viirs_annual_median_reduce(year) {\n    return ee.ImageCollection(colID).filter(    \t\tee.Filter.calendarRange(year,year,\"year\")).select(\n      \"avg_rad\").median().set('year',year)\n}\n// Map function to each year in our list\nvar yearComps = ee.ImageCollection.fromImages(years.map(viirs_annual_median_reduce))\n```\n\n8. **Importing and Exporting Data**\n\nUsing the GEE code editor is relatively straightforward for importing spatial files, such as Shapefiles. Follow the [documentation](https://developers.google.com/earth-engine/guides/table_upload?hl=en) and you should be able to import the data that you need. \n\nWhile the [documentation](https://developers.google.com/earth-engine/guides/exporting?hl=en) on exporting data is also relatively straightforward, it is important to understand exactly what you are exporting. \n\nRefer to lab 01 for more information and some examples of importing and exporting data. \n\n## Conclusion\n\nAs noted earlier, this lab is more of a JavaScript supplement to the excellent World Bank tutorial. There are many data and remote sensing libraries in Python that can help you take your work to the next stage.   \n\n\n",
   "metadata": {
    "cell_id": "2f3c8ab57e0d4e5faa3fa776832c4b58",
    "tags": [],
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 13696.46875
   }
  },
  {
   "cell_type": "markdown",
   "source": "",
   "metadata": {
    "cell_id": "a7dca71b62504fb3a78fb873c4d9574e",
    "tags": [],
    "deepnote_cell_type": "markdown",
    "deepnote_cell_height": 46
   }
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=b8aff9fa-104a-41a3-b121-f629ebd12bab' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "orig_nbformat": 2,
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_notebook_id": "e11dfa4f-e0cd-46d3-81c1-e78e64535637",
  "deepnote_execution_queue": []
 }
}